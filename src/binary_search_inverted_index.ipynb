{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c58f8680",
   "metadata": {},
   "source": [
    "# Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cddc0047",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/nico/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# Librerias para el procesamiento de lenguaje natural\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# Librerias para el procesamiento de archivos xml\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Librerias de uso general\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Librerias para tipado de funciones\n",
    "from typing import List\n",
    "\n",
    "# Configuración de palabras de parada\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Configuración de stemmer\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fd4b9c",
   "metadata": {},
   "source": [
    "# Proceso de preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bbf8bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text: str) -> List[str]:\n",
    "    # Normalización del texto\n",
    "    text = text.lower()\n",
    "    # Tokenización simple a nivel de palabra\n",
    "    tokens = re.findall(r\"\\w+\", text)\n",
    "    # Quitar stopwords y aplicar stemming\n",
    "    processed = [stemmer.stem(token) for token in tokens if token not in stop_words]\n",
    "    # Retornar texto preprocesado\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab222820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'run', 'quick', 'garden']\n"
     ]
    }
   ],
   "source": [
    "print(preprocess(\"The cats are running quickly in the gardens\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5cca6d",
   "metadata": {},
   "source": [
    "# Ingesta de documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e1e57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta en la que se encuentran los documentos a procesar\n",
    "path_docs = \"../data/test\"\n",
    "\n",
    "def load_documents(path_docs: str):\n",
    "\t# Diccionario para almacenar los documentos por id\n",
    "\tdocs = {}\n",
    "\t# Se revisan únicamente los archivos relevantes\n",
    "\tfor file_name in os.listdir(path_docs):\n",
    "\t\tif not file_name.endswith(\".naf\"):\n",
    "\t\t\tcontinue\n",
    "\t\t# Construccion del arbol de atributos del documento\n",
    "\t\ttree = ET.parse(os.path.join(path_docs, file_name))\n",
    "\t\troot = tree.getroot()\n",
    "\t\t# Id recuperado desde el atributo pupblicId\n",
    "\t\tdoc_id = root.find(\"nafHeader/public\").attrib[\"publicId\"]\n",
    "\t\t# Titulo desde el atributo title\n",
    "\t\ttitle = root.find(\"nafHeader/fileDesc\").attrib.get(\"title\", \"\")\n",
    "\t\t# Contenido desde <raw>\n",
    "\t\traw_element = root.find(\"raw\")\n",
    "\t\tcontent = raw_element.text if raw_element is not None else \"\"\n",
    "\t\t# concatenar titulo + contenido para preprocesar\n",
    "\t\ttokens = preprocess(title +  \" \" + content)\n",
    "\t\tdocs[doc_id] = tokens\n",
    "\t# Retornar los documentos cargados\n",
    "\treturn docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3d6ef18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'d001': ['william', 'beaumont', 'human', 'digest', 'william', 'beaumont', 'human', 'digest', 'william', 'beaumont', 'physiolog', 'digest', 'imag', 'sourc', 'novemb', '21', '1785', 'us', 'american', 'surgeon', 'william', 'beaumont', 'born', 'becam', 'best', 'known', 'father', 'gastric', 'physiolog', 'follow', 'research', 'human', 'digest', 'william', 'beaumont', 'born', 'lebanon', 'connecticut', 'becam', 'physician', 'serv', 'surgeon', 'mate', 'armi', 'war', '1812', 'open', 'privat', 'practic', 'plattsburgh', 'new', 'york', 'rejoin', 'armi', 'surgeon', '1819', 'beaumont', 'station', 'fort', 'mackinac', 'mackinac', 'island', 'michigan', 'earli', '1820s', 'exist', 'protect', 'interest', 'american', 'fur', 'compani', 'fort', 'becam', 'refug', 'wound', '19', 'year', 'old', 'french', 'canadian', 'fur', 'trader', 'name', 'alexi', 'st', 'martin', 'shotgun', 'went', 'accid', 'american', 'fur', 'compani', 'store', 'close', 'rang', 'june', '6th', '1822', 'st', 'martin', 'wound', 'quit', 'serious', 'stomach', 'perfor', 'sever', 'rib', 'broken', 'nobodi', 'realli', 'expect', 'young', 'man', 'would', 'surviv', 'realli', 'skin', 'around', 'st', 'martin', 'wound', 'fuse', 'hole', 'stomach', 'leav', 'perman', 'open', 'gastric', 'fistula', '1', 'beaumont', 'quick', 'notic', 'much', 'research', 'potenti', 'back', 'much', 'known', 'digest', 'system', 'order', 'gain', 'inform', 'beaumont', 'perform', 'numer', 'experi', 'st', 'martin', 'period', 'eight', 'year', 'experi', 'must', 'realli', 'uncomfort', 'man', 'insert', 'bit', 'differ', 'food', 'tie', 'string', 'hole', 'stomach', 'pull', 'period', 'observ', 'digest', 'beaumont', 'also', 'remov', 'gastric', 'juic', 'examin', 'better', 'understand', 'natur', 'beaumont', 'becam', 'father', 'gastric', 'physiolog', 'find', 'publish', 'book', 'experi', 'observ', 'gastric', 'juic', 'physiolog', 'digest', '1833', 'work', 'consid', 'basi', 'much', 'earli', 'knowledg', 'digest', 'william', 'beaumont', 'discov', 'hydrochlor', 'acid', 'main', 'chemic', 'respons', 'break', 'food', 'suggest', 'anoth', 'import', 'digest', 'chemic', 'known', 'pepsin', 'suggest', 'digest', 'chemic', 'process', 'mere', 'mechan', 'one', 'caus', 'stomach', 'muscl', 'movement', 'also', 'beaumont', 'gave', 'insight', 'emot', 'temperatur', 'physic', 'activ', 'affect', 'digest', 'beaumont', 'famous', 'patient', 'st', 'martin', 'outliv', 'scientist', 'even', 'though', 'wound', 'never', 'complet', 'heal', 'sever', 'children', 'die', 'age', '83', '2', 'yovisto', 'may', 'interest', 'video', 'lectur', 'digest', 'system']}\n"
     ]
    }
   ],
   "source": [
    "print(load_documents(path_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d0aabf",
   "metadata": {},
   "source": [
    "# Construcción de índice invertido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c1ea91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_inverted_index(docs):\n",
    "    # construcción de la estructura de indice invertido\n",
    "    inverted = defaultdict(set)\n",
    "    # Iteración sobre los doumentos cargados\n",
    "    for doc_id, tokens in docs.items():\n",
    "        # Iteración sobre los tokens de los documentos\n",
    "        for token in tokens:\n",
    "            # Población del índice\n",
    "            inverted[token].add(doc_id)\n",
    "    # Se retorna el índice construido\n",
    "    return inverted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
